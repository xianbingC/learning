### [流式系统 Chapter 01. Streaming 101](https://zhuanlan.zhihu.com/p/540902592)
#### 什么是Streaming
设计良好的流式计算系统与任何现有的批处理引擎一样，能够产生正确的、一致的、可重复的结果。 </p>
**流式计算:** 一种设计上考虑到了无限的数据集数据处理引擎 </p>
一个数据集的状态由两个重要的（也是正交的）维度来定义：cardinality基数和constitution结构。 </p>
基数决定了数据集的大小，最突出的特点是：  <br>
- 有边界数据：大小有限的数据集
- 无边界数据：大小（至少在理论上）无限的数据集 </p>
constitution结构定义了人们与数据交互的方式。一个直观的感受是，存在两个重要的主要结构: <br>
- **Table表** 给定时间点上的数据集的整体视角。传统上，SQL系统是以Table为单位进行处理的。
- **Stream流** 随时间演变，针对数据集逐个元素的视角。传统上，MapReduce一系的数据处理系统都是以流的形式处理数据。

#### 流式计算的局限性
流式计算系统一直被归入一个小众场景：提供低，一段时间后，批处理系统逐步提供正确的输出。</p>
对于那些还不熟悉Lambda架构的人来说，其基本思想是，运行批处理系统时并行启动一个流式系统，两者执行基本相同的计算。流式系统给出低延迟、不准确的结果，一段时间后，批处理系统逐步提供正确的输出。

##### Batch和Streaming的效率差异
批处理和流式计算之间的效率差异主要得益于批处理系统中额外的捆绑（increased bundling）和更高效的shuffle传输。现代
处理系统实施了复杂的优化，允许用户使用不多的计算资源来实现到极高的吞吐量水平。我们可以把批处理系统经验迁移到为无边界数据设计的系统上，让用户灵活地选择高延迟、高效率的batch处理和低延迟、低效率的streaming处理。

##### Event Time Versus Processing Time 事件时间vs.处理时间
在任何数据处理系统中，通常有两个我们关心的时间域：<br>
- **事件时间 Event time：** 事件实际发生的时间
- **处理时间 Processing Time：** 系统观察到事件的时间
大多数（并非全部）使用场景需要关注事件时间。比如随着时间的推移对用户行为进行定性，大多数计费应用，以及各种类型的异常检测。<br>

理想的环境中，事件时间和处理时间总是一致的，事件一发生就被立即处理。然而，现实并非如此，事件时间和处理时间之间的偏差不仅不是零，而且往往是基于底层输入源、执行引擎和硬件等特性的可变函数。能够影响偏移水平的事情包括以下几点：<br>

理想的环境中，事件时间和处理时间总是一致的，事件一发生就被立即处理。然而，现实并非如此，事件时间和处理时间之间的偏差不仅不是零，而且往往是基于底层输入源、执行引擎和硬件等特性的可变函数。能够影响偏移水平的事情包括以下几点：
- 共享资源的限制，如网络拥堵、网络分区或非专用(nondedicated)环境下的共享CPU
- 软件原因，如分布式系统逻辑、纷争(contention)等
- 数据本身的特点，如密钥分发、吞吐量的差异或乱序。

因此，如果根据现实世界的系统中绘制事件时间对应处理时间的曲线，最终得到的东西通常看起来有点像图中的红线。
![streaming](streaming.jpg)
图1-1. Time-domain mapping 时间域映射。x轴代表系统中的事件时间完整性；也就是说，到事件时间中的X时间为止，所有事件时间小于X的数据都被观察到。y轴代表处理时间的进度；也就是数据处理系统执行时观察到的正常时钟时间。

#### Data Processing Patterns 数据处理模式
##### Bounded Data 有边界数据
处理有边界数据在概念上是很简单的，而且大家可能都很熟悉。在图1-2中，我们从左边开始有一个充满熵的数据集。我们通过一些数据处理引擎（通常是批处理，如果是设计良好的流处理引擎也行）来运行它，比如MapReduce，最后在右边有一个新的、更有用的结构化数据集。
![bouded](bouded_data.jpg)
图1-2. 用一个经典的批处理引擎进行有边界数据处理。左边的有边界非结构化数据池通过数据处理引擎运行，在右边产生相应的结构化数据。

##### Unbounded Data: Batch 无边界数据: 批处理
###### Fixed windows 固定窗口
使用批处理引擎的重复运行来处理无边界数据集，最常见的方法是将输入数据窗口化为固定大小的窗口，然后将每个窗口作为一个单独的、有边界的数据源来处理（称为tumbling windows滚动窗口），如图1-3。
![fixed_window](fixed_window.jpg)
然而，在现实中，大多数系统仍然有一个完整性的问题需要处理，如果一些事件由于网络分区而在写入到日志的途中被延迟了怎么办？

###### Sessions 会话
会话通常被定义为(对于一个特定的用户)活跃期，终止于一个不活跃的间隙。使用批处理引擎来计算会话时，会话常常会被分割成不同的批次，如图1-4中的红色标记所示。我们可以通过增加批处理量来减少分割的数量，但代价是增加延迟。另一个选择是增加额外的逻辑来拼接之前运行的会话，但代价是进一步的复杂性。

##### Unbounded Data: Streaming 无边界数据: 流处理
流式系统是为无边界数据而生。对于许多现实世界的分布式输入源，数据不仅无边界，而且具备以下特性：
- 在事件时间方面高度无序。如果用户要按照数据发生顺序分析，就需要在管道中进行某种基于时间的shuffle。
- 具有不定的事件时间偏差。用户不能预期在某个固定的时长Y内，看到给定事件时间X的大部分数据。<br>

在处理具有这些特征的数据时，可以采取一些技巧。我一般将这些方法分为四组：时间无关、近似算法、基于处理时间的窗口和基于事件时间的窗口。

###### Time-agnostic 时间无关
时间无关的处理用于时间不相关的场景，即所有的逻辑都是数据驱动的。基本上现有的所有流系统都支持时间无关的场景。批处理系统也很适合对无边界数据源进行时间无关的处理，只需将无边界数据源切成任意的有边界数据集序列，并独立处理这些数据集。

###### Filtering 过滤
想象一下，你正在处理网络流量日志，用户想过滤掉所有不是来自某个特定域名的流量。用户在每条记录到达时查看它是否属于感兴趣的域名，不属于就丢弃。这类操作只依赖于一个单一的元素，所以无边界无序的数据源与事件时间偏差不具备相关性。

###### Inner joins 内连接
另一个与时间无关的例子是内连接，当连接两个无边界数据源时，如果用户只关心来自两源的元素的连接结果，那么业务逻辑中就没有时间因素。在看到来自第一个源的值时，可以简单地缓存到在持久化状态中；只有在另一个源的值到达时，才发出内联的记录。

###### Approximation algorithms 近似算法
第二大类方法是近似算法，如近似Top-N、流式k-means等。它们接受一个无边界的输入源，并输出数据。如果你仔细看输出的话，这些数据近似符合正确结果，近似算法的优点是，在设计上，它们开销低，并且是为无边界数据而设计。缺点是这类算法不多，而且往往很复杂，并且它们的近似性质影响了它们的效用。

###### Windowing 窗口化
- **Fixed windows (aka tumbling windows) 固定窗口（又称滚动窗口）**固定窗口将时间切成具有固定大小时间长度的片段
- **Sliding windows (aka hopping windows) 滑动窗口（又称跳动窗口）**作为固定窗口的泛化，滑动窗口由一个固定的长度和一个固定的周期来定义。
- **Sessions 会话** 作为动态窗口的一个例子，会话是由一系列的事件组成的，以大于某个超时的不活动间隙为终点。会话通常将一系列时间上相关的事件组合在一起来分析用户在一段时间内的行为。会话的长度不能被先验地定义；它们取决于所涉及的实际数据。<br>
![windowing](widowing.jpg)
图1-8. 窗口化策略。每个例子都显示了三个不同的键，展示了aligned windows对齐窗口（适用于所有数据）和unaligned windows非对齐窗口（适用于数据的一个子集）之间的区别。

###### Windowing by processing time 按处理时间窗口化
当按处理时间窗口化时，系统将传入的数据缓冲到窗口中，直到一定的处理时间过去。例如，在5分钟固定窗口的情况下，系统将缓冲数据5分钟处理时间，之后它将把在这5分钟内观察到的所有数据作为一个窗口，发送到下游进行处理。<br>

按处理时间窗口化有几个不错的特性：<br>

- 简单。实现起来非常简单，不用担心洗数据的问题。只需在数据到达时进行缓冲，并在窗口关闭时将它们发送到下游。
- 直白地判断窗口的完整性。因为系统清楚地知道一个窗口的所有输入是否被观察到，可以对一个给定的窗口是否完整做出判断。这意味着在通过处理时间进行窗口化时，不需要处理"迟到"的数据。

但是处理时间窗口化有一个非常大的缺点：如果这些数据与事件时间相关，那么这些数据必须按事件时间顺序到达，处理时间窗口才能反映真实发生的事件。不幸的是，在现实世界的分布式输入源中事件时间顺序的数据并不常见。

###### Windowing by event time 按事件时间窗口化
当用户需要用有限的、反映事件实际发生时间的区域来观察一个数据源时，就会使用事件时间窗口化。鉴于我们不知道获得某个窗口的所有数据的确切时间，那要怎么知道这个窗口的结果什么时候可以获得？事实上，我们根本不知道。对于许多类型的输入，系统可以通过类似于MillWheel、Cloud Dataflow和Flink中的watermark水印对窗口的完成性给出准确的启发式估计。但对于绝对正确性非常重要的情况（比如计费），唯一真正的选择是为管道创建者提供一种方法，以表达他们希望窗口的结果何时被实现，以及这些结果应如何随着时间的推移而被完善。

### [流式系统 Chapter 01. Streaming 102](https://zhuanlan.zhihu.com/p/59993580)
#### 水位线
水位线是事件时间中输入完整性的时间概念。换句话说，它们是系统根据当前处理的数据的事件时间判断处理进度和完整性的方法。<br>
在图1.1中，红色的Reality线本质上就是水位线。随着处理时间的推移，它跟踪事件时间完整性的进度。在概念上，可以将水位线视为函数 F(P) -> E，在处理时间中选取一个点，返回事件时间的一个点。更准确地说，对函数的输入实际上是在 Pipeline 中观察到水位线的点上游的一切的当前状态：输入源，缓冲数据，正在处理的数据等；但在概念上，将其视为从处理时间到事件时间的映射更简单。在事件时间点 E 上系统会认为事件时间小于 E 的所有数据都到齐了。
- **理想的水位线：**在完全了解所有输入数据的情况下，可以构建理想的水位线；在这种情况下，没有延迟数据；所有数据都提前或准时到达。
- **启发式水位线：**对于许多分布式输入源，完全了解输入数据是不切实际的，在这种情况下，最佳选择是提供。启发式的水位线使用任何有关输入的信息（分区，分区内排序，文件增长率等），以提供尽可能准确的进度估计。即使如此，使用启发式水位线意味着它有时可能是不正确的的，这将导致有些数据被划分为延迟数据。我们将在下面的触发器部分中了解如何处理延迟数据。
- **太慢：**当任何类型的水位线，由于已知的未处理数据（例如，由于网络带宽约束而缓慢增长的输入日志）被正确地延迟时，如果结果的计算只依赖水位线的触发，将直接导致输出结果的延迟。
- **太快：**当一个启发式水位线比实际的水位线更快的向前推进时，会导致原来没有延迟的数据变成了延迟数据。

#### 触发器
触发器用来表明在处理时间的什么适合该计算窗口的结果。用于触发的信号的示例包括：
- **水位线进度（即事件时间进度）**当水位线通过窗口的末尾时，计算结果并输出
- **处理时间进度**可以用于提供固定的周期更新，因为处理时间（不像事件时间）总是均匀地，没有延迟地进行。
- **元素计数**可以用于在窗口积累固定数量的元素后触发。
- **带标记的，或其他数据依赖触发器**即记录或记录的特性（例如，EOF元素或刷新事件）意味着需要产生输出的地方。
